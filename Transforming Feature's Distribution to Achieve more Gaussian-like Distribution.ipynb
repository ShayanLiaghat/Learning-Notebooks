{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on 3 blog posts by **Jason Brownlee** on **Machine Learning Mastery** website  \n",
    "The links to the posts are:  \n",
    "1. https://machinelearningmastery.com/power-transforms-with-scikit-learn/  \n",
    "2. https://machinelearningmastery.com/quantile-transforms-for-machine-learning/\n",
    "3. https://machinelearningmastery.com/discretization-transforms-for-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THEORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Transforms for Machine Learning  \n",
    "Machine learning algorithms like Linear Regression and Gaussian Naive Bayes assume the numerical variables have a Gaussian probability distribution.  \n",
    "you may be able to achieve better performance on a wide range of machine learning algorithms by transforming input and/or output variables to have a Gaussian or more-Gaussian distribution. **Many machine learning algorithms perform better when the distribution of variables is Gaussian**.  \n",
    "Another common reason for transformations is **to remove distributional skewness**. An un-skewed distribution is one that is roughly symmetric. This means that the probability of falling on either side of the distribution’s mean is roughly equal (Page 31, Applied Predictive Modeling, 2013).  \n",
    "**Power transforms** refer to a class of techniques that use a power function (like a logarithm or exponent) to make the probability distribution of a variable Gaussian or more-Gaussian like.  \n",
    "removing a skew in the distribution = stabilizing the variance of the distribution  \n",
    "There are two popular approaches for such automatic power transforms; they are: ***Box-Cox Transform*** & ***Yeo-Johnson Transform***  \n",
    "These power transforms are available in the scikit-learn Python machine learning library via the **PowerTransformer** class.  \n",
    "The class takes an argument named “**method**” that can be set to ‘yeo-johnson‘ or ‘box-cox‘ for the preferred method. It will also standardize the data automatically after the transform, meaning **each variable will have a zero mean and unit variance**. This can be turned off by setting the “standardize” argument to False.  \n",
    "  \n",
    "***Box-Cox Transform***  \n",
    "The Box-Cox transform is named for the two authors of the method.  \n",
    "It is a power transform that assumes the values of the input variable to which it is applied are **strictly positive**. That means **0 and negative values are not supported**.  \n",
    "To solve the 0 and negative value problem, we can use a **MixMaxScaler transform** first to scale the data to positive values, then apply the transform.  \n",
    "  \n",
    "***Yeo-Johnson Transform***  \n",
    "The Yeo-Johnson transform is also named for the authors.\n",
    "Unlike the Box-Cox transform, it **does not require** the values for each input variable to be strictly positive. **It supports zero values and negative values**.  \n",
    "Sometimes a lift in performance can be achieved by first standardizing the raw dataset prior to performing a Yeo-Johnson transform. We can explore this by adding a **StandardScaler** as a first step in the pipeline.  \n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantile Transforms for Machine Learning  \n",
    "A quantile transform will map a variable’s probability distribution to another probability distribution.  \n",
    "Recall that a **quantile function**, also called a percent-point function (PPF), is the inverse of the cumulative probability distribution (CDF). A CDF is a function that returns the probability of a value at or below a given value. The PPF is the inverse of this function and returns the value at or below a given probability.  \n",
    "The quantile function ranks or **smooths out** the relationship between observations and can be mapped onto other distributions, such as the **uniform** or **normal** distribution.  \n",
    "This quantile transform is available in the scikit-learn Python machine learning library via the **QuantileTransformer** class.  \n",
    "The class has an “**output_distribution**” argument that can be set to “uniform” or “normal” and defaults to “uniform“.  \n",
    "It also provides a “**n_quantiles**” that determines the resolution of the mapping or ranking of the observations in the dataset. This must be set to a value less than the number of observations in the dataset and defaults to 1,000.  \n",
    "It centers the values on **the mean value of 0 and a standard deviation of 1.0**.  \n",
    "  \n",
    "**Normal Quantile Transform**  \n",
    "We can apply the Quantile transform using the QuantileTransformer class and set the “output_distribution” argument to “normal“. We must also set the “n_quantiles” argument to a value less than the number of observations in the training dataset.  \n",
    "  \n",
    "**Uniform Quantile Transform**  \n",
    "Sometimes it can be beneficial to transform a highly exponential or multi-modal distribution to have a uniform distribution.\n",
    "This is especially useful for data with a large and sparse range of values, e.g. **outliers that are common rather than rare**.\n",
    "We can apply the transform by defining a QuantileTransformer class and setting the “output_distribution” argument to “uniform” (the default).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretization Transforms for Machine Learning  \n",
    "it is often desirable to transform each input variable to have a standard probability distribution.  \n",
    "One approach is to use transform of the numerical variable to have a discrete probability distribution where each numerical value is assigned a label and the labels have an ordered (ordinal) relationship.  \n",
    "This is called a **binning** or a **discretization** transform and can improve the performance of some machine learning models for datasets by making the probability distribution of numerical input variables discrete.  \n",
    "A **discretization transform** will map numerical variables onto discrete values. Values for the variable are grouped together into discrete bins and each bin is assigned a unique integer such that the ordinal relationship between the bins is preserved. The use of bins is often referred to as **binning or k-bins**, where k refers to the number of groups to which a numeric variable is mapped.  \n",
    "Different methods for grouping the values into k discrete bins can be used; common techniques include:  \n",
    "**Uniform**: Each bin has the same width in the span of possible values for the variable.  \n",
    "**Quantile**: Each bin has the same number of values, split based on percentiles.  \n",
    "**Clustered**: Clusters are identified and examples are assigned to each group.  \n",
    "The discretization transform is available in the scikit-learn Python machine learning library via the **KBinsDiscretizer** class.  \n",
    "The “**strategy**” argument controls the manner in which the input variable is divided, as either “uniform,” “quantile,” or “kmeans.”  \n",
    "The “**n_bins**” argument controls the number of bins that will be created and must be set based on the choice of strategy, e.g. **“uniform” is flexible**, “quantile” must have a “n_bins” less than the number of observations or sensible percentiles, and “kmeans” must use a value for the number of clusters that can be reasonably found.  \n",
    "The “**encode**” argument controls whether the transform will map each value to an integer value by setting “**ordinal**” or a one-hot encoding “**onehot**”. An ordinal encoding is almost always preferred, although a one-hot encoding may allow a model to learn non-ordinal relationships between the groups, such as in the case of k-means clustering strategy.  \n",
    "  \n",
    "**Uniform Discretization Transform**  \n",
    "A uniform discretization transform will preserve the probability distribution of each input variable but will make it discrete with the specified number of ordinal groups or labels.  \n",
    "  \n",
    "**K-means Discretization Transform**  \n",
    "A K-means discretization transform will attempt to fit k clusters for each input variable and then assign each observation to a cluster. Unless the empirical distribution of the variable is complex, the number of clusters is likely to be small, such as 3-to-5.  \n",
    "  \n",
    "**Quantile Discretization Transform**  \n",
    "A quantile discretization transform will attempt to split the observations for each input variable into k groups, where the number of observations assigned to each group is approximately equal. Unless there are a large number of observations or a complex empirical distribution, the number of bins must be kept small, such as 5-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaya\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\shaya\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\shaya\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Original: 0.8144\n",
      "Standard Deviation Original: 0.0725\n"
     ]
    }
   ],
   "source": [
    "# for practice, we will use the Sonar Dataset which is available on Jason's Github.\n",
    "# It involves 60 real-valued inputs and a 2-class target variable. \n",
    "# There are 208 examples in the dataset and the classes are reasonably balanced.\n",
    "# K-nearest neighbor is used as the base model to compare the transformations\n",
    "\n",
    "# load the dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv\"\n",
    "dataset = pd.read_csv(url, header=None)\n",
    "\n",
    "# pd.dataframe to np.array\n",
    "data = dataset.values\n",
    "\n",
    "# separating input and output\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "\n",
    "# ensuring the input is float and output is integer\n",
    "X = X.astype('float32')\n",
    "y = LabelEncoder().fit_transform(y.astype('str'))\n",
    "\n",
    "# defining the model\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=1)\n",
    "n_scores_original = cross_val_score(model,X,y,scoring='accuracy',cv=cv,n_jobs=-1, error_score='raise')\n",
    "print(f'Accuracy Original: {round(np.mean(n_scores_original),4)}\\nStandard Deviation Original: {round(np.std(n_scores_original),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Box-Cox: 0.821\n",
      "Standard Deviation Box-Cox: 0.0644\n"
     ]
    }
   ],
   "source": [
    "# Box-Cox transformation\n",
    "from sklearn.preprocessing import PowerTransformer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# definign the pipeline\n",
    "scaler = MinMaxScaler(feature_range=(1,2))\n",
    "power = PowerTransformer(method='box-cox')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline_box_cox = Pipeline(steps=[('s',scaler),('p',power),('m',model)])\n",
    "\n",
    "# model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=1)\n",
    "n_scores_box_cox = cross_val_score(pipeline_box_cox,X,y,scoring='accuracy',cv=cv,n_jobs=-1, error_score='raise')\n",
    "print(f'Accuracy Box-Cox: {round(np.mean(n_scores_box_cox),4)}\\nStandard Deviation Box-Cox: {round(np.std(n_scores_box_cox),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Yeo-Johnson: 0.821\n",
      "Standard Deviation Yeo-Johnson: 0.0644\n"
     ]
    }
   ],
   "source": [
    "# Yeo-Johnson trasformation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# definign the pipeline\n",
    "scaler = StandardScaler()\n",
    "power = PowerTransformer(method='yeo-johnson')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline_yeo_johnson = Pipeline(steps=[('s',scaler),('p',power),('m',model)])\n",
    "\n",
    "# model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=1)\n",
    "n_scores_yeo_johnson = cross_val_score(pipeline_yeo_johnson,X,y,scoring='accuracy',cv=cv,n_jobs=-1, error_score='raise')\n",
    "print(f'Accuracy Yeo-Johnson: {round(np.mean(n_scores_box_cox),4)}\\nStandard Deviation Yeo-Johnson: {round(np.std(n_scores_box_cox),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Normal Quntile Transformation: 0.817\n",
      "Standard Deviation Normal Quntile Transformation: 0.088\n"
     ]
    }
   ],
   "source": [
    "# Normal Quantile Transformation\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# definign the pipeline\n",
    "normal_quantile_transform = QuantileTransformer(n_quantiles=100,output_distribution='normal')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline_normal_quantile = Pipeline(steps=[('t',normal_quantile_transform),('m',model)])\n",
    "\n",
    "# model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=1)\n",
    "n_scores_normal_quantile = cross_val_score(pipeline_normal_quantile,X,y,scoring='accuracy',cv=cv,n_jobs=-1, error_score='raise')\n",
    "print(f'Accuracy Normal Quntile Transformation: {round(np.mean(n_scores_normal_quantile),4)}\\nStandard Deviation Normal Quntile Transformation: {round(np.std(n_scores_normal_quantile),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Uniform Quntile Transformation: 0.8452\n",
      "Standard Deviation Uniform Quntile Transformation: 0.0624\n"
     ]
    }
   ],
   "source": [
    "# Uniform Quantile Transformation\n",
    "\n",
    "# definign the pipeline\n",
    "uniform_quantile_transform = QuantileTransformer(n_quantiles=100,output_distribution='uniform')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline_uniform_quantile = Pipeline(steps=[('t',uniform_quantile_transform),('m',model)])\n",
    "\n",
    "# model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=1)\n",
    "n_scores_uniform_quantile = cross_val_score(pipeline_uniform_quantile,X,y,scoring='accuracy',cv=cv,n_jobs=-1, error_score='raise')\n",
    "print(f'Accuracy Uniform Quntile Transformation: {round(np.mean(n_scores_uniform_quantile),4)}\\nStandard Deviation Uniform Quntile Transformation: {round(np.std(n_scores_uniform_quantile),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose the number of quantiles as an arbitrary number, in this case, 100.  \n",
    "This hyperparameter can be tuned to explore the effect of the resolution of the transform on the resulting skill of the model.  \n",
    "The example below performs this experiment and plots the mean accuracy for different “n_quantiles” values from 1 to 99.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     accuracy:    0.46617, std: 0.01234\n",
      "2     accuracy:    0.83222, std: 0.07477\n",
      "3     accuracy:    0.84491, std: 0.06908\n",
      "4     accuracy:    0.85317, std: 0.06092\n",
      "5     accuracy:    0.85143, std: 0.06359\n",
      "6     accuracy:    0.84485, std: 0.05811\n",
      "7     accuracy:    0.83849, std: 0.06157\n",
      "8     accuracy:    0.84841, std: 0.0617\n",
      "9     accuracy:    0.84675, std: 0.06212\n",
      "10    accuracy:    0.84167, std: 0.06514\n",
      "11    accuracy:    0.84024, std: 0.06219\n",
      "12    accuracy:    0.84039, std: 0.06309\n",
      "13    accuracy:    0.84198, std: 0.06409\n",
      "14    accuracy:    0.84206, std: 0.06503\n",
      "15    accuracy:     0.8419, std: 0.06043\n",
      "16    accuracy:    0.84183, std: 0.0632\n",
      "17    accuracy:    0.84356, std: 0.06385\n",
      "18    accuracy:    0.84198, std: 0.06526\n",
      "19    accuracy:    0.84198, std: 0.06409\n",
      "20    accuracy:    0.84031, std: 0.06308\n",
      "21    accuracy:    0.84039, std: 0.06428\n",
      "22    accuracy:    0.84515, std: 0.06238\n",
      "23    accuracy:    0.84039, std: 0.06428\n",
      "24    accuracy:    0.84356, std: 0.06385\n",
      "25    accuracy:    0.84356, std: 0.06266\n",
      "26    accuracy:    0.84515, std: 0.06238\n",
      "27    accuracy:    0.84198, std: 0.06409\n",
      "28    accuracy:    0.84356, std: 0.06385\n",
      "29    accuracy:    0.84356, std: 0.06266\n",
      "30    accuracy:    0.84515, std: 0.06238\n",
      "31    accuracy:    0.84183, std: 0.0621\n",
      "32    accuracy:    0.84356, std: 0.06266\n",
      "33    accuracy:    0.84039, std: 0.06428\n",
      "34    accuracy:    0.84515, std: 0.06238\n",
      "35    accuracy:    0.84356, std: 0.06385\n",
      "36    accuracy:    0.84198, std: 0.06409\n",
      "37    accuracy:    0.84348, std: 0.06018\n",
      "38    accuracy:    0.84515, std: 0.06238\n",
      "39    accuracy:    0.84515, std: 0.06238\n",
      "40    accuracy:    0.84515, std: 0.06238\n",
      "41    accuracy:    0.84356, std: 0.06385\n",
      "42    accuracy:    0.84356, std: 0.06266\n",
      "43    accuracy:    0.84674, std: 0.06206\n",
      "44    accuracy:    0.84198, std: 0.06409\n",
      "45    accuracy:     0.8419, std: 0.06431\n",
      "46    accuracy:    0.84356, std: 0.06266\n",
      "47    accuracy:    0.84515, std: 0.06238\n",
      "48    accuracy:    0.84356, std: 0.06266\n",
      "49    accuracy:    0.84356, std: 0.06266\n",
      "50    accuracy:    0.84515, std: 0.06238\n",
      "51    accuracy:    0.84515, std: 0.06238\n",
      "52    accuracy:    0.84515, std: 0.06238\n",
      "53    accuracy:    0.84356, std: 0.06266\n",
      "54    accuracy:    0.84515, std: 0.06238\n",
      "55    accuracy:    0.84674, std: 0.06206\n",
      "56    accuracy:    0.84356, std: 0.06385\n",
      "57    accuracy:    0.84674, std: 0.06206\n",
      "58    accuracy:    0.84515, std: 0.06238\n",
      "59    accuracy:    0.84515, std: 0.06238\n",
      "60    accuracy:    0.84515, std: 0.06238\n",
      "61    accuracy:    0.84198, std: 0.06409\n",
      "62    accuracy:    0.84356, std: 0.06385\n",
      "63    accuracy:    0.84515, std: 0.06238\n",
      "64    accuracy:    0.84674, std: 0.06206\n",
      "65    accuracy:    0.84356, std: 0.06385\n",
      "66    accuracy:    0.84515, std: 0.06238\n",
      "67    accuracy:    0.84515, std: 0.06238\n",
      "68    accuracy:    0.84515, std: 0.06238\n",
      "69    accuracy:    0.84356, std: 0.06385\n",
      "70    accuracy:    0.84515, std: 0.06238\n",
      "71    accuracy:    0.84348, std: 0.06289\n",
      "72    accuracy:    0.84356, std: 0.06385\n",
      "73    accuracy:    0.84515, std: 0.06238\n",
      "74    accuracy:    0.84674, std: 0.06206\n",
      "75    accuracy:    0.84515, std: 0.06238\n",
      "76    accuracy:    0.84356, std: 0.06385\n",
      "77    accuracy:    0.84356, std: 0.06385\n",
      "78    accuracy:    0.84515, std: 0.06238\n",
      "79    accuracy:    0.84515, std: 0.06238\n",
      "80    accuracy:    0.84356, std: 0.06385\n",
      "81    accuracy:    0.84515, std: 0.06238\n",
      "82    accuracy:    0.84515, std: 0.06238\n",
      "83    accuracy:    0.84198, std: 0.06409\n",
      "84    accuracy:    0.84356, std: 0.06385\n",
      "85    accuracy:    0.84356, std: 0.06385\n",
      "86    accuracy:    0.84356, std: 0.06385\n",
      "87    accuracy:    0.84356, std: 0.06385\n",
      "88    accuracy:    0.84356, std: 0.06385\n",
      "89    accuracy:    0.84348, std: 0.06289\n",
      "90    accuracy:    0.84515, std: 0.06238\n",
      "91    accuracy:    0.84515, std: 0.06238\n",
      "92    accuracy:    0.84674, std: 0.06206\n",
      "93    accuracy:    0.84356, std: 0.06385\n",
      "94    accuracy:    0.84515, std: 0.06238\n",
      "95    accuracy:    0.84356, std: 0.06385\n",
      "96    accuracy:    0.84515, std: 0.06238\n",
      "97    accuracy:    0.84515, std: 0.06238\n",
      "98    accuracy:    0.84515, std: 0.06238\n",
      "99    accuracy:    0.84356, std: 0.06385\n"
     ]
    }
   ],
   "source": [
    "models = dict()\n",
    "for i in range(1,100):\n",
    "    trans = QuantileTransformer(n_quantiles=i, output_distribution='uniform')\n",
    "    model = KNeighborsClassifier()\n",
    "    models[str(i)] = Pipeline(steps=[('t', trans), ('m', model)])\n",
    "    \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "results = list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model)\n",
    "    results.append(np.mean(scores))\n",
    "    print(f'{name:{5}} accuracy: {round(np.mean(scores),5):{10}}, std: {round(np.std(scores),5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28a79311a88>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3hcd33n8fdXo4sv8kWW5Lsdy/ckTuIkwoltoGkgjgk0ZkuXJrTbpA80sK2hhVA2ecoGMOUp9LLQ3ccLcYgJ5VkwIaUgWtMQAiHBzkUydkzkxLYsO5asxNbF8lWWNDPf/WOORnOTNbKlKDn+vJ5nHs0553dmfkdn9JmfvnPmHHN3REQkvApGuwMiIjKyFPQiIiGnoBcRCTkFvYhIyCnoRURCrnC0O5CpoqLC582bN9rdEBF5S9mxY0ebu1fmWvamC/p58+ZRV1c32t0QEXlLMbNXB1qm0o2ISMgp6EVEQk5BLyIScgp6EZGQU9CLiIScgl5EJOQU9CIiIZdX0JvZWjPba2YNZnZfjuVzzeyXZrbTzHab2W3B/Hlm1mVmu4LbN4Z7A4Zqe0Mb3689zOsnzo12V0RE3hCDfmHKzCLARuAWoBmoNbMad9+T0uyzwKPu/nUzuwLYCswLlh1w9+XD2+0Ls/f1U/zpI7V0R+MALJ0+gQ/dMJc/WTlvdDsmIjKC8hnRrwAa3L3R3XuALcC6jDYOTAzuTwJahq+Lw6OrJ8b67/6GCWOKePSjK7n/PUsZWxzhgR/X89DTjeddtzcWf4N6KSIy/PIJ+llAU8p0czAv1eeBPzazZhKj+Y+nLKsKSjq/MrN35HoCM7vHzOrMrK61tTX/3g/BF35ST0Prab72h8tZUTWFj/7OAh772Cree/UMvrT1ZR6ta8q5Xs2LLSz57E953/95hq/85ys819iOrsr15nbqXC/HTr25SnNne6IcajuTNd/dOdh2hq6e2LA+3+nuKIfbzw7rY+brbE+UfUdPEQ3pAOnkuV6aOkbnd3uh8jnXjeWYl5l0dwKPuPs/mdlK4Dtmtgx4DZjr7u1mdj3wIzO70t1Ppj2Y+yZgE0B1dfWwp2jNiy1sqW3iz29awNsXVSTnRwqMr35wOSe7ernvX3czaWwRt145Pbn8xNlevlBTz/zKUsYVF/LQ0418/akD/P51s/i737+KksLIcHf1or1wsIPy0mIWVJYO2rY3Fmd38wlaT3Vz89KpFBcO/r7f0tnFzsOdXD17EnOmjMurT00dZ6lvOcn1l5VROaHkvG3dnUPtZ6k91JEssWVaWFnKdZdNzvr9n+mO8sj2Q3zjVweIxZ2//4Ored/VMwd9vv3HTlPfcoIl0yaydPoECgqyX/Jtp7t5rrGd42d7cz5OZWkJN86fwuRxxQD0ROO82NzJtoY2tje0s7PpOL0x5+0LK/j0rUtYPmcydYc6+IfH9/L8wQ6KIwVcO3cyKxeUU16a+3d07ZzJLJs1Keey7miMnYc72d7QxrYD7bzY1Ek07ty8dCr3rlnMlTMn4e40HDvNzsOddOcIYQMWTS3l2rllydfCibO9PH+wnaJIASuqpjC+JDsyemNxXmzqZFtDO9sOtLHzcGJbJ5QUcsP8KaxaUMHqhRUsnlaKWfbv9tjJczx3sIMTXf2/2zllY3nbvP7n6+qJUXuog1dTAraytIRbrphGJMf+ulhdPTGeP9hO0/Gu5LzXT3SxraGd3x45QSzurLliGveuWcKS6RNwd/YePcXLr53k8hkTWTJtQnJbj3R28cLBdk53534zn102lhXzcv9uh4sNNjoNgvvz7n5rMH0/gLv/XUqbemCtuzcF043Aje5+LOOxngI+7e4DnrWsurrah/OkZme6o7z9K7+gqmI83//oSooi2WF2pjvKHz/8PPVHTrL57rcl3wz+5t9+y/deOMxPPv52rpw5idPdUR56upF/fnI/1ZeV8Y3/dj0VA/xRXojXT5zjV/uO0XDsNNfOLWPl/HLKxhfntW40FuefntjH1586wJiiAr7ygatZt3xWctm/7TzCbw53JtsfPXmOFw52cLo7CsCcKWP55LsXs275LNpOd7P9QBu7DnfSE0u8PrqjMX7z6nEOBaPE4kgBf7LyMtbfvJAJY4p4sbmTZ/a1MX1SCb9/3ezk7/k/X3qNT/9gd/J5lkybwMoF5axeWMEN86cwcUwRx06d4/nGDp5tbOeZ/a00dfT/cQ2kpLCAt82bknyzicedJ185StvpHt59+TSOn+1hx6vH+cjbq/gf71matt+PnjzHM/vbeGZ/K9sPtNN6qju5bMr4Ym6cP4VJY4uTv7vdzSfYe/TUoH0yg2UzJ1E2vpi6Qx2c7YlhBlfNmsTKBeVMHFPE5l8fpP1MD4unlbLv6GkqSkv4yDuq6DjTw7aGNva8dpLz/UmuvXI6965ZzPzKUupbTrCtoZ3tB9qoPdTBud44BQZXz57M6oXllBRGePjXBznR1csNVVM42HaGYynbOpCxRRGq55VxoquXl46cIB70pyhiXH9ZGUunTyTuTjTutHR28cLB/m1dNnMSqxaWs7CylJ1NiTeevtdMRWkxN1SVM3FsEdD/BrH/2Omc/SiKGMvnTKbAjJ2HO+nJ8ea0cGop996ymLXLpnOks4vtB9r5bfMJovGhjRfNoLDAKDCj4dhpXjjUQU/GQCNSYFwzexKrF1ZgZnzr1wc53RPlxqpy9h87RdvpnmTbitJils8pY/+xU7yax39WhQWJbX33FdP42O8sGFLf+7fBdrh7dc5leQR9IbAPeBdwBKgFPuTu9Sltfgp8390fMbPLgSdJlHcqgA53j5nZfOAZ4Cp37xjo+YY76B96upEvbX2ZH/75Kq6bWzZgu86zPdyx6TlebT/Lv3x4BUWRAv7L/93Gn66q4oHfuyKt7X/sfo17f7CL8vEl/OnqeVTPm8KVMycmwyQeT7y7b2to47nGdo6e7CYWd2JxxwyKCwsojhRQGDEiwYur9VQ3r7yeCJNIgSXbLppaytjixDt9xOCaOZN556JKbpg/hXHB/PbT3Xxiy062NbTzh9VzONh2hhcOdXD3qnlcf1kZX31iH41tZygbV0Rh0MeJYwq5cX4icIsiBXzt5/uobznJpLFFyZFVaUkhY4sTo+aC5B9xBdfMnsSjdU38YEczpSWFFBZY2kh37pRx/NW7F7H36Cke/FUj18yZzGduXcKLzZ1sb2hPjtYLDKZPHENLcARUaUkhKxeU885FFaxcUMGkIBBSxeLOS0dOsO1AG88eaKf9TP8f19LpE/jkLYu5bm4ZPdE4X/qPPXz72Ve5rHwc5eOLKSwo4PjZnmSwVJSWsHphOasWlHPVrMnsee0k2w+0UXfoOF29idGXAYunTWDVwnJWL6hg5uSxWX1ynMPtZ5Mj2hNne5Mj2ZXzy5k0rn87znRH+da2g/z0pdd539UzuWvVZcn9CImSS64yTm8szqN1TXzzmYOc6YlSWlLIqXOJN8/F00qTo+a+N88+J7p6efiZRra+9DpXzJjI6oXlrKgqpzTH6DEW92AftfH8wQ4mjClMPm5PNM4z+1v51b5WjnR2UViQeO1OHlfMyvnlrF5Yzo3zy5P/0aQ60tkV/GfTRt2rx5P/qRmwdMZEVi8oZ9WCCqZPGpP4fXrf3087zx5oI+ae7Mfl0/tHyrWHOvinn+3lQOsZJo8rojN4DU4YU8iYoqH9t+2e+PuMxp2Zk8byjkUVvGNxZdrzjS+JpO2rzrM9PPh0I0/sOcqymRNZtbCCZTMn8VLLCbY3tPFi8wkWVI5n1YIKVi0sp3x89qDQcfa9fpptBxK/n/LSEjbf/bYh9b3PRQV98AC3AV8DIsBmd/+SmW0A6ty9JjjS5iGglERZ5zPu/jMz+wCwAYgCMeBz7v6T8z3XcAb9ud4Y7/j7X7Joainf/bMbB23fdrqbDz74LMdOdjN1YglnuqM8ee9NOf8odjd3cu+jLyZDo6SwgHHFEXpjTnc0Rm8wEq6qGM+88nFECgqIFIA79MTi9ETjRGNOLHiBlZYUsnphBTctqWTh1FJ2N/e9WDqTj9XVG+PFpk66o3EKC4ySwgKiwYszUmD87fuX8cHqOfTG4nz5p6/w8K8PAolR9KfWLGbNFdNy/usMiTenn770Oo/Xv86yWRNZtaCCK2ZMzFnG6PPK6yfZ+MsDFBUYv7OkkncuqmRXUyf/+LO91LckqnN/dMNcHvi9K9LKLIn/DjrZfqCNxtYzXDNnEjdUlXPlzInJN6Lh8uNdR/i3nUcSv+u4M6aogBvnl/POxZUsTfkjfqvoONPDw79upONMDzfOL2flgnKmThgz2t0aNbG488PfNPPrhjaumT35vCWit4JY8Ld8IS466N9Iwxn033nuVf7nj17iux+5gVULKwZfgUT55L8+uJ2mji42fug63nv1jPO2P3ryHHWHjvObw8fpicYpLiygKFLAgsrxrF6YewR4Mc71JmqVzzW2090bJ1JgFEaM266awZUz0+u3T758lLM9MW67asaI1DEHEo87P9tzFHDWLjv/709EhsclGfS9sTg3/cNTTJ1Ywg//+6ohvcO/dqKLukPHed/VM96yIwMRubScL+hDewqEml0tHOnsYv3vLhxyWM+YNJbfu2amQl5EQiG0Qf/g0we4fMZEbl46dbS7IiIyqkIb9A3HTnPz0kqNykXkkhfKoI/HnbiT85h5EZFLTSiTsO/LEoVv4JEmIiJvVqEM+lhf0GtELyISzqCPxhPfvNOIXkQkpEHfN6J/I78kJCLyZhXKoO87ZYBG9CIiIQ161ehFRPqFMgn7avQq3YiIhDToYzq8UkQkKZRB31ej14heRCSkQd83otc3Y0VEQhr0qtGLiPTLK+jNbK2Z7TWzBjO7L8fyuWb2SzPbaWa7gytS9S27P1hvr5ndOpydH4hq9CIi/Qa97LiZRYCNwC1AM1BrZjXuviel2WeBR93968FlBbcC84L7dwBXAjOBn5vZYnfPfTn0YaIavYhIv3xG9CuABndvdPceYAuwLqONAxOD+5OAluD+OmCLu3e7+0GgIXi8EaUavYhIv3yScBbQlDLdHMxL9Xngj82smcRo/uNDWBczu8fM6sysrrW1Nc+uD0w1ehGRfvkEfa60zLzQ7J3AI+4+G7gN+I6ZFeS5Lu6+yd2r3b26srIyjy6dn2r0IiL9Bq3RkxiFz0mZnk1/aabPh4G1AO7+rJmNASryXHfYRVWjFxFJymdEXwssMrMqMysm8eFqTUabw8C7AMzscmAM0Bq0u8PMSsysClgEvDBcnR9IVDV6EZGkQUf07h41s/XA40AE2Ozu9Wa2Aahz9xrgXuAhM/skidLM3e7uQL2ZPQrsAaLAX4z0ETcAMdXoRUSS8ind4O5bSXzImjrvgZT7e4DVA6z7JeBLF9HHIdOlBEVE+oWytqEavYhIv3AGvWr0IiJJoUxC1ehFRPqFMuhVoxcR6RfOoFeNXkQkKZxBr2vGiogkhTIJ+2r0Kt2IiIQ06PtG9CrdiIiENehj+jBWRKRPOINeI3oRkaRQBn0sHqewwDBT0IuIhDLoo3HXaF5EJBDOoI+56vMiIoFQBn0s7jqGXkQkEMo0jAY1ehERCWnQx1SjFxFJCmXQ96pGLyKSlFfQm9laM9trZg1mdl+O5V81s13BbZ+ZdaYsi6Usy7zW7IhQjV5EpN+glxI0swiwEbgFaAZqzawmuHwgAO7+yZT2HweuTXmILndfPnxdHlw0rhG9iEiffIa9K4AGd2909x5gC7DuPO3vBL43HJ27ULF4XDV6EZFAPkE/C2hKmW4O5mUxs8uAKuAXKbPHmFmdmT1nZu8fYL17gjZ1ra2teXZ9YL0xfRgrItInn6DPlZg+QNs7gMfcPZYyb667VwMfAr5mZguyHsx9k7tXu3t1ZWVlHl06v1jcdb1YEZFAPmnYDMxJmZ4NtAzQ9g4yyjbu3hL8bASeIr1+PyJ0CgQRkX75BH0tsMjMqsysmESYZx09Y2ZLgDLg2ZR5ZWZWEtyvAFYDezLXHW4xfWFKRCRp0KNu3D1qZuuBx4EIsNnd681sA1Dn7n2hfyewxd1TyzqXAw+aWZzEm8qXU4/WGSmq0YuI9Bs06AHcfSuwNWPeAxnTn8+x3nbgqovo3wWJxZ2xRZE3+mlFRN6UQvmJpWr0IiL9Qhn0qtGLiPQLZdBHVaMXEUkKZ9DrOHoRkaRQpqFOUywi0i+UQa8Lj4iI9Atn0KtGLyKSFM6g1/noRUSSQpmGMZ2PXkQkKZRBH43pfPQiIn3CGfQa0YuIJIU36FWjFxEBQhr0qtGLiPQLXdC7u74wJSKSInRBH40nToevEb2ISELogj7WF/Sq0YuIAHkGvZmtNbO9ZtZgZvflWP5VM9sV3PaZWWfKsrvMbH9wu2s4O5+LRvQiIukGvcKUmUWAjcAtJC4UXmtmNamXBHT3T6a0/zjBBcDNbArwOaAacGBHsO7xYd2KFLFYIuhVoxcRSchnRL8CaHD3RnfvAbYA687T/k7ge8H9W4En3L0jCPcngLUX0+HB9MbjABRGFPQiIpBf0M8CmlKmm4N5WczsMqAK+MVQ1jWze8yszszqWltb8+n3gJI1+gLV6EVEIL+gzzU09gHa3gE85u6xoazr7pvcvdrdqysrK/Po0sBUoxcRSZdP0DcDc1KmZwMtA7S9g/6yzVDXHRaq0YuIpMsn6GuBRWZWZWbFJMK8JrORmS0ByoBnU2Y/DqwxszIzKwPWBPNGjGr0IiLpBj3qxt2jZraeREBHgM3uXm9mG4A6d+8L/TuBLe7uKet2mNkXSbxZAGxw947h3YR0qtGLiKQbNOgB3H0rsDVj3gMZ058fYN3NwOYL7N+QRVW6ERFJE7phb0wfxoqIpAld0PfV6COq0YuIACEM+r4RfZFq9CIiQAiDXjV6EZF0oQv6/rNXKuhFRCCEQZ+s0WtELyIChDDo+74Zqxq9iEhC6NKw71w3GtGLiCSELuhVoxcRSRe6oI+qRi8ikiZ8Qa8avYhImtClYV/pRt+MFRFJCF3Q68IjIiLpQhj0qtGLiKQKX9CrRi8ikiZ0aagavYhIutAFvWr0IiLp8gp6M1trZnvNrMHM7hugzQfNbI+Z1ZvZd1Pmx8xsV3DLutbscIvGVKMXEUk16KUEzSwCbARuAZqBWjOrcfc9KW0WAfcDq939uJlNTXmILndfPsz9HpBG9CIi6fIZ0a8AGty90d17gC3Auow2fwZsdPfjAO5+bHi7mb9Y3IkUGGYKehERyC/oZwFNKdPNwbxUi4HFZrbNzJ4zs7Upy8aYWV0w//25nsDM7gna1LW2tg5pAzJFg6AXEZGEQUs3QK7U9ByPswi4CZgNPGNmy9y9E5jr7i1mNh/4hZn91t0PpD2Y+yZgE0B1dXXmYw9JNBZX2UZEJEU+I/pmYE7K9GygJUebH7t7r7sfBPaSCH7cvSX42Qg8BVx7kX0+r2jcFfQiIinyCfpaYJGZVZlZMXAHkHn0zI+A3wUwswoSpZxGMyszs5KU+auBPYygWNwpjITuqFERkQs2aOnG3aNmth54HIgAm9293sw2AHXuXhMsW2Nme4AY8Nfu3m5mq4AHzSxO4k3ly6lH64wE1ehFRNLlU6PH3bcCWzPmPZBy34FPBbfUNtuBqy6+m/lTjV5EJF3oahyJ0o2CXkSkT+iCPvFhbOg2S0TkgoUuEWOq0YuIpAld0PeqRi8ikiZ0Qa8avYhIutAFfeLwytBtlojIBQtdIsb0zVgRkTShC/reWFwfxoqIpAhd0MfiTpFq9CIiSaELetXoRUTShS4RVaMXEUkXuqBXjV5EJF3ogl41ehGRdKEMetXoRUT6hS4RdYUpEZF04Qt61ehFRNLkFfRmttbM9ppZg5ndN0CbD5rZHjOrN7Pvpsy/y8z2B7e7hqvjA4mqRi8ikmbQK0yZWQTYCNxC4iLgtWZWk3pJQDNbBNwPrHb342Y2NZg/BfgcUA04sCNY9/jwb0qCTlMsIpIunxH9CqDB3RvdvQfYAqzLaPNnwMa+AHf3Y8H8W4En3L0jWPYEsHZ4up6bLjwiIpIun0ScBTSlTDcH81ItBhab2TYze87M1g5h3WGlGr2ISLp8Lg6eKzU9x+MsAm4CZgPPmNmyPNfFzO4B7gGYO3duHl0aWFTnoxcRSZPPiL4ZmJMyPRtoydHmx+7e6+4Hgb0kgj+fdXH3Te5e7e7VlZWVQ+l/Fp0CQUQkXT5BXwssMrMqMysG7gBqMtr8CPhdADOrIFHKaQQeB9aYWZmZlQFrgnkjwt11UjMRkQyDlm7cPWpm60kEdATY7O71ZrYBqHP3GvoDfQ8QA/7a3dsBzOyLJN4sADa4e8dIbAgkRvOARvQiIinyqdHj7luBrRnzHki578CnglvmupuBzRfXzfxE+4JeNXoRkaRQ1Tg0ohcRyRaqoO8b0atGLyLSL1SJGI3FAY3oRURShSroY6rRi4hkCVXQR1WjFxHJEqqgj6lGLyKSJVSJ2KsavYhIllAFvWr0IiLZQhX0qtGLiGQLVdCrRi8iki1UiagavYhItlAFvWr0IiLZQhX0/adAUNCLiPQJVdD3n9QsVJslInJRQpWIfTV6jehFRPqFKuj7RvRFqtGLiCSFKuhVoxcRyZZX0JvZWjPba2YNZnZfjuV3m1mrme0Kbh9JWRZLmZ95rdlhpRq9iEi2QS8laGYRYCNwC9AM1JpZjbvvyWj6fXdfn+Mhutx9+cV3dXCq0YuIZMtn6LsCaHD3RnfvAbYA60a2WxdGNXoRkWz5BP0soCllujmYl+kDZrbbzB4zszkp88eYWZ2ZPWdm78/1BGZ2T9CmrrW1Nf/eZ1CNXkQkWz5Bnys1PWP6J8A8d78a+Dnw7ZRlc929GvgQ8DUzW5D1YO6b3L3a3asrKyvz7Ho21ehFRLLlk4jNQOoIfTbQktrA3dvdvTuYfAi4PmVZS/CzEXgKuPYi+nteUdXoRUSy5BP0tcAiM6sys2LgDiDt6Bkzm5EyeTvwcjC/zMxKgvsVwGog80PcYRNVjV5EJMugR924e9TM1gOPAxFgs7vXm9kGoM7da4BPmNntQBToAO4OVr8ceNDM4iTeVL6c42idYRNTjV5EJMugQQ/g7luBrRnzHki5fz9wf471tgNXXWQf8xZVjV5EJEuoElE1ehGRbOEKel1KUEQkS6iCPhZ3CgwKFPQiIkmhCvpo3FWfFxHJEKpUjMbiqs+LiGQIV9DHXdeLFRHJEKqgj8VdH8SKiGQIVdBH405ENXoRkTShSsVoLK4RvYhIhnAFvWr0IiJZQhX0qtGLiGQLVdAnavQKehGRVOEK+lhcX5gSEckQqlSMqUYvIpIlVEEfVY1eRCRLqII+phq9iEiWvILezNaa2V4zazCz+3Isv9vMWs1sV3D7SMqyu8xsf3C7azg7n6lXNXoRkSyDXmHKzCLARuAWEhcKrzWzmhyXBPy+u6/PWHcK8DmgGnBgR7Du8WHpfYZY3CmKKOhFRFLlk4orgAZ3b3T3HmALsC7Px78VeMLdO4JwfwJYe2FdHZwOrxQRyZZP0M8CmlKmm4N5mT5gZrvN7DEzmzPEdYeFvjAlIpItn6DPlZyeMf0TYJ67Xw38HPj2ENbFzO4xszozq2ttbc2jS7n1xnRSMxGRTPmkYjMwJ2V6NtCS2sDd2929O5h8CLg+33WD9Te5e7W7V1dWVubb9yyxeJwiHUcvIpImn6CvBRaZWZWZFQN3ADWpDcxsRsrk7cDLwf3HgTVmVmZmZcCaYN6IUI1eRCTboEfduHvUzNaTCOgIsNnd681sA1Dn7jXAJ8zsdiAKdAB3B+t2mNkXSbxZAGxw944R2A5ANXoRkVwGDXoAd98KbM2Y90DK/fuB+wdYdzOw+SL6mLeoavQiIllClYpR1ehFRLKEKuh1CgQRkWyhCnqd1ExEJFu4gl41ehGRLKFKRdXoRUSyhSroVaMXEckWqqBXjV5EJFtogj4Wd9xRjV5EJENoUjEajwPomrEiIhlCE/SxeOKkmCrdiIikC03QR4Og14exIiLpwhP0MY3oRURyCU3QRwqM9141g6rK0tHuiojIm0peZ698K5g0toiNf3TdaHdDRORNJzQjehERyU1BLyIScgp6EZGQyyvozWytme01swYzu+887f7AzNzMqoPpeWbWZWa7gts3hqvjIiKSn0E/jDWzCLARuAVoBmrNrMbd92S0mwB8Ang+4yEOuPvyYeqviIgMUT4j+hVAg7s3unsPsAVYl6PdF4G/B84NY/9EROQi5RP0s4CmlOnmYF6SmV0LzHH3f8+xfpWZ7TSzX5nZO3I9gZndY2Z1ZlbX2tqab99FRCQP+QR9rq+aenKhWQHwVeDeHO1eA+a6+7XAp4DvmtnErAdz3+Tu1e5eXVlZmV/PRUQkL/l8YaoZmJMyPRtoSZmeACwDnjIzgOlAjZnd7u51QDeAu+8wswPAYqBuoCfbsWNHm5m9OqStSFcBtF3E+m9V2u5Li7b70pLPdl820AJz94GWJRqYFQL7gHcBR4Ba4EPuXj9A+6eAT7t7nZlVAh3uHjOz+cAzwFXu3jFIhy+YmdW5e/VIPf6blbb70qLtvrRc7HYPOqJ396iZrQceByLAZnevN7MNQJ2715xn9XcCG8wsCsSAj41kyIuISLa8znXj7luBrRnzHhig7U0p9/8V+NeL6J+IiFykMH4zdtNod2CUaLsvLdruS8tFbfegNXoREXlrC+OIXkREUijoRURCLjRBn++J197qzGyOmf3SzF42s3oz+8tg/hQze8LM9gc/y0a7ryPBzCLBN63/PZiuMrPng+3+vpkVj3Yfh5uZTTazx8zslWC/r7yE9vcng9f5S2b2PTMbE8Z9bmabzeyYmb2UMi/nPraE/x1k3W4zG/SKS6EI+pQTr70HuAK408yuGN1ejZgocK+7Xw7cCPxFsK33AU+6+yLgyWA6jP4SeDll+ivAV4PtPg58eFR6NbL+GfhPd18KXENi+0O/v81sFokTJVa7+zISh3ffQTj3+SPA2ox5A+3j9wCLgts9wNcHe/BQBD35n3jtLc/dX3P33wT3T5H4o59FYnu/HTT7NvD+0enhyDGz2cB7gW8G0wbcDDwWNHzGF+wAAAJLSURBVAnddgenDHkn8DCAu/e4eyeXwP4OFAJjgy9ujiNxWpXQ7XN3fxrI/I7RQPt4HfAvnvAcMNnMZpzv8cMS9IOeeC2MzGwecC2JU0NPc/fXIPFmAEwdvZ6NmK8BnwHiwXQ50Onu0WA6jPt9PtAKfCsoWX3TzMZzCexvdz8C/CNwmETAnwB2EP593megfTzkvAtL0J/3xGthZGalJL6M9lfufnK0+zPSzOx9wDF335E6O0fTsO33QuA64OvByQHPEMIyTS5BTXodUAXMBMaTKFtkCts+H8yQX/dhCfrBTrwWKmZWRCLk/5+7/zCYfbTv37fg57HR6t8IWQ3cbmaHSJTmbiYxwp8c/FsP4dzvzUCzu/dd0OcxEsEf9v0N8G7goLu3unsv8ENgFeHf530G2sdDzruwBH0tsCj4NL6YxAc25zsHz1tWUJd+GHjZ3f9XyqIa4K7g/l3Aj9/ovo0kd7/f3We7+zwS+/cX7v5HwC+BPwiahXG7XweazGxJMOtdwB5Cvr8Dh4EbzWxc8Lrv2/ZQ7/MUA+3jGuBPgqNvbgRO9JV4BuTuobgBt5E4y+YB4G9Guz8juJ1vJ/Fv2m5gV3C7jUS9+klgf/Bzymj3dQR/BzcB/x7cnw+8ADQAPwBKRrt/I7C9y0mc2ns38COg7FLZ38AXgFeAl4DvACVh3OfA90h8DtFLYsT+4YH2MYnSzcYg635L4qik8z6+ToEgIhJyYSndiIjIABT0IiIhp6AXEQk5Bb2ISMgp6EVEQk5BLyIScgp6EZGQ+//oHwrtw5mXyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Uniform Discretization Transformation: 0.8451\n",
      "Standard Deviation Uniform Discretization Transformation: 0.0732\n"
     ]
    }
   ],
   "source": [
    "# Uniform Discretization Transformation\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# definign the pipeline\n",
    "uniform_discretizer = KBinsDiscretizer(n_bins=10,encode='ordinal',strategy='uniform')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline_uniform_discretizer = Pipeline(steps=[('t',uniform_discretizer),('m',model)])\n",
    "\n",
    "# model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=1)\n",
    "n_scores_uniform_discretizer = cross_val_score(pipeline_uniform_discretizer,X,y,scoring='accuracy',cv=cv,n_jobs=-1, error_score='raise')\n",
    "print(f'Accuracy Uniform Discretization Transformation: {round(np.mean(n_scores_uniform_discretizer),4)}\\nStandard Deviation Uniform Discretization Transformation: {round(np.std(n_scores_uniform_discretizer),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy K-means Discretization Transformation: 0.8224\n",
      "Standard Deviation K-means Discretization Transformation: 0.0795\n"
     ]
    }
   ],
   "source": [
    "# K-means Discretization Transformation\n",
    "\n",
    "# definign the pipeline\n",
    "kmeans_discretizer = KBinsDiscretizer(n_bins=3,encode='ordinal',strategy='kmeans')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline_kmeans_discretizer = Pipeline(steps=[('t',kmeans_discretizer),('m',model)])\n",
    "\n",
    "# model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=1)\n",
    "n_scores_kmeans_discretizer = cross_val_score(pipeline_kmeans_discretizer,X,y,scoring='accuracy',cv=cv,n_jobs=-1, error_score='raise')\n",
    "print(f'Accuracy K-means Discretization Transformation: {round(np.mean(n_scores_kmeans_discretizer),4)}\\nStandard Deviation K-means Discretization Transformation: {round(np.std(n_scores_kmeans_discretizer),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Qantile Discretization Transformation: 0.8449\n",
      "Standard Deviation Qantile Discretization Transformation: 0.0678\n"
     ]
    }
   ],
   "source": [
    "# Quantile Discretization Transformation\n",
    "\n",
    "# definign the pipeline\n",
    "quantile_discretizer = KBinsDiscretizer(n_bins=10,encode='ordinal',strategy='quantile')\n",
    "model = KNeighborsClassifier()\n",
    "pipeline_quantile_discretizer = Pipeline(steps=[('t',quantile_discretizer),('m',model)])\n",
    "\n",
    "# model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=1)\n",
    "n_scores_quantile_discretizer = cross_val_score(pipeline_quantile_discretizer,X,y,scoring='accuracy',cv=cv,n_jobs=-1, error_score='raise')\n",
    "print(f'Accuracy Qantile Discretization Transformation: {round(np.mean(n_scores_quantile_discretizer),4)}\\nStandard Deviation Qantile Discretization Transformation: {round(np.std(n_scores_quantile_discretizer),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose the number of bins as an arbitrary number; in this case, 10.  \n",
    "This hyperparameter can be tuned to explore the effect of the resolution of the transform on the resulting skill of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2     accuracy:    0.82547, std: 0.06784\n",
      "3     accuracy:    0.86407, std: 0.06537\n",
      "4     accuracy:    0.84841, std: 0.06928\n",
      "5     accuracy:    0.84644, std: 0.06797\n",
      "6     accuracy:       0.84, std: 0.04908\n",
      "7     accuracy:    0.85159, std: 0.06092\n",
      "8     accuracy:    0.84833, std: 0.06696\n",
      "9     accuracy:    0.84667, std: 0.05719\n",
      "10    accuracy:    0.84493, std: 0.06775\n"
     ]
    }
   ],
   "source": [
    "models = dict()\n",
    "for i in range(2,11):\n",
    "    trans = KBinsDiscretizer(n_bins=i, encode='ordinal', strategy='quantile')\n",
    "    model = KNeighborsClassifier()\n",
    "    models[str(i)] = Pipeline(steps=[('t', trans), ('m', model)])\n",
    "    \n",
    "def evaluate_model(model):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print(f'{name:{5}} accuracy: {round(np.mean(scores),5):{10}}, std: {round(np.std(scores),5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x28a7acb9f48>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7acc1f08>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ace2d88>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ace61c8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad10e88>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad13d08>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad38108>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad30a48>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad5fcc8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad10cc8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad7e9c8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad8c048>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7b1602c8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ac72d88>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7aaf9308>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ab46348>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ac7a808>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7aabe388>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x28a7acc1108>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7acc4808>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7acea748>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7acf3e88>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad17d48>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad1cfc8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad350c8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad3fe88>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad63388>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad17f88>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7a7bae48>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ac89d88>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ac81a88>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ac81c48>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7aad9888>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7aad5b88>,\n",
       "  <matplotlib.lines.Line2D at 0x28a79fe3e08>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7aab2b08>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x28a7acb6908>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7acda048>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad030c8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad30308>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad57408>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad74988>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ac9b948>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ab17788>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ac7a908>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x28a7acccfc8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7acf3f88>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad10848>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad47fc8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad6a1c8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ac8c9c8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ac6e108>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7aac6cc8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7a9b0388>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x28a7acdae88>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad00e08>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad1fa08>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad4bb48>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad70848>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ac90488>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7aaf4308>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7a9a9ec8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7a9efe08>],\n",
       " 'means': [<matplotlib.lines.Line2D at 0x28a7acd02c8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7acf8448>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad24288>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad47248>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad74b88>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ad89dc8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7ab11dc8>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7a03e048>,\n",
       "  <matplotlib.lines.Line2D at 0x28a7a99e1c8>]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(results,labels=names,showmeans=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
